{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 21:27:26.466266: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 21:27:26.529904: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 21:27:28.111525: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42) # NEVER change this line\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow built with CUDA: True\n",
      "GPUs detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPUs detected:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train_df = pd.read_csv('train.csv', engine='python')\n",
    "\n",
    "# create function to clearn the input text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Get the 20000 most common words to tokenize\n",
    "MAX_WORDS = 20000\n",
    "# For each comment, we want the length to be 200. If it is more, it will be cut short, if it is less, it will be padded\n",
    "MAX_LEN = 200\n",
    "\n",
    "# create Keras tokenizer and set num_words parameter\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
    "# toeknize 20000 most common words (remove symbols and excess spaces)\n",
    "tokenizer.fit_on_texts(train_df['comment_text'].apply(clean_text))\n",
    "\n",
    "# convert each comment to a sequence of 200 numeric word ID's\n",
    "X_data = pad_sequences(tokenizer.texts_to_sequences(train_df['comment_text']), maxlen=MAX_LEN)\n",
    "# select the label columns for our y_train ds and convert to numpy matrix where each row corresponds to a single comments labels\n",
    "y_data = train_df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178839\n",
      "44710\n"
     ]
    }
   ],
   "source": [
    "# using iterative stratification, which balances the label combinations across splits.\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134129\n",
      "44710\n"
     ]
    }
   ],
   "source": [
    "# using iterative stratification, which balances the label combinations across splits.\n",
    "X_train, y_train, X_val, y_val = iterative_train_test_split(X_train, y_train, test_size=0.25)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('float32')\n",
    "y_val = y_val.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "class totals: [12830.  1177.  7284.   413.  6782.  1259.]\n",
      "total samples: 134129\n",
      "Class weights: {0: 1.7423876331514678, 1: 18.993061455678276, 2: 3.069032582829947, 3: 54.127925746569815, 4: 3.2962007274157084, 5: 17.75602329891448}\n"
     ]
    }
   ],
   "source": [
    "labels = train_df.drop(columns=['id','comment_text']).columns.to_list()\n",
    "print(f'labels: {labels}')\n",
    "\n",
    "class_totals = np.sum(y_train, axis=0)\n",
    "print(f'class totals: {class_totals}')\n",
    "\n",
    "total_samples = y_train.shape[0]\n",
    "print(f'total samples: {total_samples}')\n",
    "\n",
    "class_weights = {i: total_samples / (len(labels) * class_totals[i]) for i in range(len(labels))}\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.ones_like(y_train, dtype='float32')\n",
    "for i in range(len(labels)):\n",
    "    sample_weights[:, i] = y_train[:, i] * class_weights[i]\n",
    "\n",
    "# print(sample_weights)\n",
    "\n",
    "# If sample_weights has shape (num_samples, 6)\n",
    "sample_weights_flat = np.mean(sample_weights, axis=1).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=MAX_WORDS + 1, output_dim=128, input_length=MAX_LEN),\n",
    "        LSTM(128, recurrent_activation='sigmoid', use_bias=True),\n",
    "        Dropout(0.2),\n",
    "        Dense(len(labels), activation='sigmoid', dtype='float32')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']  # list or dict matching output names\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_callbacks():\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)\n",
    "    ]\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train, sample_weights_flat)) \\\n",
    "    .shuffle(10000).batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)) \\\n",
    "    .batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)) \\\n",
    "    .batch(128).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (134129, 6)\n",
      "sample_weights shape: (134129, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"sample_weights shape:\", sample_weights.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shapes: (128, 200) (128, 6) (128,)\n"
     ]
    }
   ],
   "source": [
    "for x, y, w in train_ds.take(1):\n",
    "    print(\"Batch shapes:\", x.shape, y.shape, w.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 20ms/step - accuracy: 0.9828 - loss: 0.0736 - val_accuracy: 0.9782 - val_loss: 0.8054 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.9753 - loss: 0.0550 - val_accuracy: 0.9890 - val_loss: 0.6592 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.9776 - loss: 0.0462 - val_accuracy: 0.9743 - val_loss: 0.5324 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.9584 - loss: 0.0399 - val_accuracy: 0.9839 - val_loss: 0.6455 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.9499 - loss: 0.0340 - val_accuracy: 0.9709 - val_loss: 0.6343 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.9543 - loss: 0.0273 - val_accuracy: 0.9690 - val_loss: 0.5562 - learning_rate: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "callbacks = build_callbacks()\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9720 - loss: 0.5443\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "imported_model = keras.models.load_model(\"model.keras\")\n",
    "\n",
    "test_accuracy, test_loss = imported_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "[[0.8790848  0.03531715 0.2806723  0.3012795  0.2905284  0.03107408]]\n",
      "['toxic']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"You are so annoying. I hope I never see a comment from you again\"\n",
    "# Clean\n",
    "cleaned = clean_text(sentence)\n",
    "\n",
    "# Convert to sequence\n",
    "seq = tokenizer.texts_to_sequences([cleaned])  # note the list\n",
    "\n",
    "# Pad sequence\n",
    "padded_seq = pad_sequences(seq, maxlen=MAX_LEN)\n",
    "\n",
    "# Predict\n",
    "prediction = imported_model.predict(padded_seq)\n",
    "print(prediction)\n",
    "\n",
    "threshold = 0.5\n",
    "predicted_labels = [labels[i] for i, p in enumerate(prediction[0]) if p > threshold]\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.10      1.00      0.17      4277\n",
      " severe_toxic       0.38      0.38      0.38       392\n",
      "      obscene       0.27      0.87      0.41      2428\n",
      "       threat       0.12      0.66      0.21       138\n",
      "       insult       0.20      0.86      0.32      2261\n",
      "identity_hate       0.09      0.66      0.16       438\n",
      "\n",
      "    micro avg       0.13      0.89      0.23      9934\n",
      "    macro avg       0.19      0.74      0.28      9934\n",
      " weighted avg       0.17      0.89      0.27      9934\n",
      "  samples avg       0.08      0.09      0.08      9934\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict on validation/test set\n",
    "y_pred = (imported_model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
